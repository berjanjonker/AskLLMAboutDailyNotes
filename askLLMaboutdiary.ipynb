{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea0cf28",
   "metadata": {},
   "source": [
    "A script to analyze a diary file day-by-day with a local large language model (LLM)\n",
    "\n",
    "See https://www.transformingmed.tech/p/decoding-happiness-an-ai-driven-experiment\n",
    "\n",
    "Matthijs Cluitmans for Transforming Med.Tech (http://transformingmed.tech/)\n",
    "\n",
    "Steps:\n",
    "- Install LM Studio (https://lmstudio.ai/)\n",
    "- In LM Studio, find a suitable LLM that fits with the specs of your computer. LM Studio will tell you if it will run or not. I used the Vicuna LLM (vicuna-13b-v1.5-16k.Q5_K_M.gguf) from Hugging Face https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGUF\n",
    "- In LM Studio, go to Local Inference Server, load the model (with the appropriate preset, e.g. Vicuna 1.5 16k), and start the server\n",
    "- Than run this Jupyter notebook with your local copy of diary.csv, which contains two columns: Date and Tekst, semicolon separated (;) and is an UTF-8 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f727ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Matthijs Cluitmans for Transforming Med.Tech (http://transformingmed.tech/)\n",
    "\n",
    "\n",
    "import openai\n",
    "import csv\n",
    "\n",
    "# Put your URI end point:port here for your local inference server (in LM Studio) \n",
    "openai.api_base='http://localhost:1234/v1'\n",
    "# Put in an empty API Key\n",
    "openai.api_key=''\n",
    "\n",
    "# Adjust the following based on the model type\n",
    "# Alpaca style prompt format (suitable for Vicuna):\n",
    "prefix = \"### Instruction:\\n\" \n",
    "suffix = \"\\n### Response:\"\n",
    "\n",
    "# 'Llama2 Chat' prompt format (required for some other LLMs):\n",
    "#prefix = \"[INST]\"\n",
    "#suffix = \"[/INST]\"\n",
    "\n",
    "temperature = 0 # Vary the temperature if needed; but higher temp gives more hallucinations. I had best results at 0\n",
    "\n",
    "# Simple wrapper function for prompts\n",
    "def get_completion(prompt, messages, model=\"local model\", temperature=0.0):\n",
    "    formatted_prompt = f\"{prefix}{prompt}{suffix}\"\n",
    "    messages.extend([{\"role\": \"user\", \"content\": formatted_prompt}])\n",
    "    #print(messages)\n",
    "    #print(f'\\nYour prompt: {prompt}\\n')\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        n_predict=-1,\n",
    "        repeat_penalty=1.1\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "# These are the prompts I run on every dairy input. Adapt to your needs (e.g., now it assumes Dutch input but will respond in English.)\n",
    "systemprompt = 'You are a thorough and truthful assistant that analyses psychological content of a diary.'\n",
    "prompts = []\n",
    "prompts.append('I will give you a part of a diary in Dutch. We\\'re going to analyse the elements that display happiness or unhappiness. We\\'ll do that in a few steps. First, please extract a single \"happiness score\" from 1-10 that reflects how happy the user seems to be that day, 1 being very unhappy and 10 being very happy. Only provide number as output, nothing else, so just a single number. If you do not have sufficient information, respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a single \"gratefulness score\" from 1-10 that reflects how grateful the user seems to be that day, 1 being not grateful at all and 10 being very grateful. Only provide number as output, nothing else, so just a single number. If you do not have sufficient information, respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, provide a few summarizing keywords (in English, separated by commas) that characterize the main experiences that made the user happy. Keep your response short. If you do not have sufficient information, respond \"blank\" and do not make up content that was not provided by the user. Only provide the keywords as output, nothing else. Respond in English.')\n",
    "prompts.append('Now, based on the diary, provide a few summarizing keywords (in English, separated by commas) that characterize the main experiences that made the user unhappy. Keep your response short. If you do not have sufficient information, respond \"blank\" and do not make up content that was not provided by the user. Only provide the keywords as output, nothing else. Respond in English.')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for the weather that day, 1 being very bad weather, 5 being very good weather. Only provide number as output, nothing else, so just a single number. If you do not have information about the weather (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for how busy the user was that day, 1 being not busy at all, 5 being extremely busy. Only provide number as output, nothing else, so just a single number. If you do not have information about busyness (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for how the user enjoyed spending time with family that day, 1 indicating not at all, 5 indicating a lot. Only provide number as output, nothing else, so just a single number. If you do not have information about family time (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for how the user enjoyed work that day, 1 indicating not at all, 5 indicating a lot. Only provide number as output, nothing else, so just a single number. If you do not have information about work satisfaction (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for how much family time the user had that day, 1 indicating no family time at all, 5 indicating spending the whole day with the family. Only provide number as output, nothing else, so just a single number. If you do not have information about family (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please extract a score from 1-5 for how much the health of the user or of his family affected them that day, 1 indicating not at all, 5 indicating a lot. Only provide number as output, nothing else, so just a single number. If you do not have information about family (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n",
    "prompts.append('Now, based on the diary, please use a few keywords (in English, separated by commas) that could help determine personality traits that are apparent from this text. If none are available (which may be likely), respond with \"blank\" only and nothing else (no explanation is required).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read diary, ask prompt, write output to new file\n",
    "# Create output file: I had to enforce utf-8 and fix some weird emoticons in my diary.\n",
    "with open('diaryLLMoutput.txt', 'a', encoding=\"utf-8\") as outputfile:\n",
    "    outputfile.write('\\n\\n-----------------------------\\n NEW RUN\\n-----------------------------')\n",
    "    # Opening the diary file, also as UTF-8 and with ; as delimiter\n",
    "    with open('diary.csv', newline='', encoding=\"UTF-8\") as csvfile:\n",
    "        diaryreader = csv.reader(csvfile, delimiter=';')\n",
    "        line_count = 0\n",
    "        system_prompt = {\"role\": \"system\", \"content\": systemprompt}\n",
    "        messages = [system_prompt] # initialize with system prompt\n",
    "        for row in diaryreader:\n",
    "            if line_count > 0:\n",
    "                messages = [system_prompt] # start over again PER DAY (I also tried to retain a few days but this did not improve results considerably)\n",
    "                response = []\n",
    "                print('\\nProcessing ' + row[0])\n",
    "                # Remark: processing takes a long time, much longer than what you're expected from cloud-based solutions such as ChatGPT. So be patient.\n",
    "                for i in range(len(prompts)):\n",
    "                    if i==0:\n",
    "                        prompt = prompts[0] + '\\n\\n' + row[1]\n",
    "                    else:\n",
    "                        prompt = prompts[i]\n",
    "                    # Store the response\n",
    "                    response.append(get_completion(prompt, messages=messages, temperature=temperature))\n",
    "                    messages.extend([{\"role\": \"assistant\", \"content\": response[i]}]) \n",
    "                # Write the response to the file\n",
    "                outputfile.write('\\n' + row[0] + ';')\n",
    "                for x in response:\n",
    "                    outputfile.write(x+ ';')\n",
    "                outputfile.flush()\n",
    "            line_count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53264c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
